{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignement 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anja Deric and Karan Soni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABSTRACT\n",
    "\n",
    "For this assignment, we worked on collecting data from social media to complement our already existing data on flights, airports and airlines. Additionally, we also converted our previous database to NoSQL by connecting to a MongoDB server. FOr the first part of the assignment, we used the Twitter API to collect data on various topics related to our domain, including tweets about American Airlines (thing), Logan Airport (place), and pilots (people). We used Python to analyze this tweet data and determine what tags were most popular and trending within our domain. For the second half of the assignment, we imported our old data from Assignments 1 and 2, and along with our newly-collected twitter data, we converted everything into a NoSQL database. By connecting to a MongoDB server, we were also able to test and make sure some of database usecases worked and could provide information requested by the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Social Media Data\n",
    "\n",
    "To start the assignment, we first imported all libraries that we would be using throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then made a twitter developer account and used our keys and tokens to establish a connection with the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API keys and tokens\n",
    "consumer_key = \"mGtIt09UVXyzyW5LMBx6YKSIg\"  \n",
    "consumer_secret = \"DCi2axya3I6iRdxLvnNzPbInscCA7oquTaZKJqSK2WOCDriwjp\"  \n",
    "access_token = \"1238579197867524096-EhwxltGCsYmzWsDYoW9JsIqT3Yghck\"  \n",
    "access_token_secret = \"2EBkSz2GRrC8w0tdpPxKEVGC4swpAQsDDoNkUMbKresIg\"\n",
    "\n",
    "# Establish connection with twitter API using developer keys\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)  \n",
    "auth.set_access_token(access_token, access_token_secret)  \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we wrote a function to collect 100 tweets (combination of most popular and most recent tweets) by making an API request using the Cursor function from the tweepy library. The function works by searching for tweets that have a specific search term in them, which the user can decide on. Each tweet is then stored in a dictionary (we collected information such as the username, tweet test, number of retweets, hashtags, etc.). The function, in the end, returns all the tweets as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to collect information on 100 tweets that contain a particular search term\n",
    "def get_tweets(search_term):\n",
    "    all_tweets = []\n",
    "    # Make API request for tweets in English that contain search_term\n",
    "    for tweet in tweepy.Cursor(api.search, q=search_term,lang = \"en\").items(100):\n",
    "        # Store all tweets in dictionary\n",
    "        all_tweets += [{ 'Tweet_id': tweet.id,\n",
    "                'Screen_name':tweet.author.screen_name,\n",
    "                'Created_at':tweet.created_at,\n",
    "                'Tweet_text':tweet.text,\n",
    "                'Hashtags':re.findall(r\"#(\\w+)\",tweet.text),\n",
    "                'Retweets':tweet.retweet_count,\n",
    "                'Favorites':tweet.favorite_count,\n",
    "                'Location':tweet.user.location}]\n",
    "    # Return all tweets in dataframe format\n",
    "    return pd.DataFrame(all_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we used our function to collect 100 tweets relating to American Airlines, Logan Airport, and pilots, all terms related to our domain. To ensure our funciton worked, we additionally used the .head() method to check the first few tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Screen_name</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1247229042371297281</td>\n",
       "      <td>AMERICA_PARTII</td>\n",
       "      <td>2020-04-06 18:25:50</td>\n",
       "      <td>RT @KelliRenard: American Arlines won’t refund...</td>\n",
       "      <td>[]</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1247227986627215362</td>\n",
       "      <td>michael83747287</td>\n",
       "      <td>2020-04-06 18:21:39</td>\n",
       "      <td>Thanks @Delta @SouthwestAir and @AlaskaAir for...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1247225304864743424</td>\n",
       "      <td>Cjkbeauty</td>\n",
       "      <td>2020-04-06 18:10:59</td>\n",
       "      <td>Fighting with @AmericanAir all day to get a re...</td>\n",
       "      <td>[AmericanAirlines]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pittsburgh, Pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1247222584468557826</td>\n",
       "      <td>Lake25246548</td>\n",
       "      <td>2020-04-06 18:00:11</td>\n",
       "      <td>https://t.co/d7XCgMIYkl\\nFarewell 757/adios 75...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1247215366088134656</td>\n",
       "      <td>PKOPEC17</td>\n",
       "      <td>2020-04-06 17:31:30</td>\n",
       "      <td>RT @AJC4others: We may have found out first bo...</td>\n",
       "      <td>[AmericanAirlines]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None, Piemonte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_id      Screen_name          Created_at  \\\n",
       "0  1247229042371297281   AMERICA_PARTII 2020-04-06 18:25:50   \n",
       "1  1247227986627215362  michael83747287 2020-04-06 18:21:39   \n",
       "2  1247225304864743424        Cjkbeauty 2020-04-06 18:10:59   \n",
       "3  1247222584468557826     Lake25246548 2020-04-06 18:00:11   \n",
       "4  1247215366088134656         PKOPEC17 2020-04-06 17:31:30   \n",
       "\n",
       "                                          Tweet_text            Hashtags  \\\n",
       "0  RT @KelliRenard: American Arlines won’t refund...                  []   \n",
       "1  Thanks @Delta @SouthwestAir and @AlaskaAir for...                  []   \n",
       "2  Fighting with @AmericanAir all day to get a re...  [AmericanAirlines]   \n",
       "3  https://t.co/d7XCgMIYkl\\nFarewell 757/adios 75...                  []   \n",
       "4  RT @AJC4others: We may have found out first bo...  [AmericanAirlines]   \n",
       "\n",
       "   Retweets  Favorites        Location  \n",
       "0        10          0                  \n",
       "1         0          0                  \n",
       "2         0          0  Pittsburgh, Pa  \n",
       "3         0          0                  \n",
       "4         2          0  None, Piemonte  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 100 tweews on American Airlines (thing)\n",
    "all_tweets = get_tweets(\"#AmericanAirlines\")\n",
    "airline_tweets = all_tweets\n",
    "airline_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Screen_name</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1246797293338136576</td>\n",
       "      <td>RWayneLopez</td>\n",
       "      <td>2020-04-05 13:50:13</td>\n",
       "      <td>Coming Soon 45 Province PH3B for lease at $12,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1246614553535922181</td>\n",
       "      <td>BOS_Boston_Limo</td>\n",
       "      <td>2020-04-05 01:44:05</td>\n",
       "      <td>First class premium car services Boston, MA\\nh...</td>\n",
       "      <td>[loganairport]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1246595470417371138</td>\n",
       "      <td>LisaAFerrari</td>\n",
       "      <td>2020-04-05 00:28:15</td>\n",
       "      <td>Looking for the place that moved so I can drop...</td>\n",
       "      <td>[loganairport, bostonfishpier]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Boston,MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1246164233240354816</td>\n",
       "      <td>jb_SID</td>\n",
       "      <td>2020-04-03 19:54:40</td>\n",
       "      <td>26,000 people departed #LoganAirport last week...</td>\n",
       "      <td>[LoganAirport, Covid]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1246117138659545089</td>\n",
       "      <td>getmybuzzup</td>\n",
       "      <td>2020-04-03 16:47:32</td>\n",
       "      <td>The #newenglandpatriots plane just touched dow...</td>\n",
       "      <td>[newenglandpatriots, loganairport, boston, n95...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yonkers, NY, CT, NJ, ATL, LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_id      Screen_name          Created_at  \\\n",
       "0  1246797293338136576      RWayneLopez 2020-04-05 13:50:13   \n",
       "1  1246614553535922181  BOS_Boston_Limo 2020-04-05 01:44:05   \n",
       "2  1246595470417371138     LisaAFerrari 2020-04-05 00:28:15   \n",
       "3  1246164233240354816           jb_SID 2020-04-03 19:54:40   \n",
       "4  1246117138659545089      getmybuzzup 2020-04-03 16:47:32   \n",
       "\n",
       "                                          Tweet_text  \\\n",
       "0  Coming Soon 45 Province PH3B for lease at $12,...   \n",
       "1  First class premium car services Boston, MA\\nh...   \n",
       "2  Looking for the place that moved so I can drop...   \n",
       "3  26,000 people departed #LoganAirport last week...   \n",
       "4  The #newenglandpatriots plane just touched dow...   \n",
       "\n",
       "                                            Hashtags  Retweets  Favorites  \\\n",
       "0                                                 []         0          1   \n",
       "1                                     [loganairport]         0          1   \n",
       "2                     [loganairport, bostonfishpier]         0          1   \n",
       "3                              [LoganAirport, Covid]         0          0   \n",
       "4  [newenglandpatriots, loganairport, boston, n95...         0          0   \n",
       "\n",
       "                       Location  \n",
       "0                    Boston, MA  \n",
       "1                    Boston, MA  \n",
       "2                     Boston,MA  \n",
       "3                        Boston  \n",
       "4  Yonkers, NY, CT, NJ, ATL, LA  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 100 tweews on Logan Airport (place)\n",
    "all_tweets = get_tweets(\"#LoganAirport\")\n",
    "airport_tweets = all_tweets\n",
    "airport_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Screen_name</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1247210121354186759</td>\n",
       "      <td>saltydogsbot</td>\n",
       "      <td>2020-04-06 17:10:39</td>\n",
       "      <td>RT @JadeEyePanda: #Titanfall #fanart Legionnai...</td>\n",
       "      <td>[Titanfall, fanart, Modo, 3DArt, art, mecha, m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1247209812389224452</td>\n",
       "      <td>JadeEyePanda</td>\n",
       "      <td>2020-04-06 17:09:25</td>\n",
       "      <td>#Titanfall #fanart Legionnaire WIP 4 #Modo #3D...</td>\n",
       "      <td>[Titanfall, fanart, Modo, 3DArt, art, mecha, m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Buena Park, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1247208734767616003</td>\n",
       "      <td>luisevanegas</td>\n",
       "      <td>2020-04-06 17:05:09</td>\n",
       "      <td>RT @Fiicaan: Kalitta operated month old 777F h...</td>\n",
       "      <td>[avgeek, aviationphoto]</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Desearía estar en #MiEspaña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1247207541173555200</td>\n",
       "      <td>aeromarinetax</td>\n",
       "      <td>2020-04-06 17:00:24</td>\n",
       "      <td>Aircraft, Vessels, or Vehicles-How Out of Stat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Elk Grove, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1247204199647055872</td>\n",
       "      <td>PlaneSpotIsCool</td>\n",
       "      <td>2020-04-06 16:47:07</td>\n",
       "      <td>RT @BBSAirport: We can’t wait to get back to d...</td>\n",
       "      <td>[StaySafe, Airport, Timelapse, BusinessAviatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Worldwide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_id      Screen_name          Created_at  \\\n",
       "0  1247210121354186759     saltydogsbot 2020-04-06 17:10:39   \n",
       "1  1247209812389224452     JadeEyePanda 2020-04-06 17:09:25   \n",
       "2  1247208734767616003     luisevanegas 2020-04-06 17:05:09   \n",
       "3  1247207541173555200    aeromarinetax 2020-04-06 17:00:24   \n",
       "4  1247204199647055872  PlaneSpotIsCool 2020-04-06 16:47:07   \n",
       "\n",
       "                                          Tweet_text  \\\n",
       "0  RT @JadeEyePanda: #Titanfall #fanart Legionnai...   \n",
       "1  #Titanfall #fanart Legionnaire WIP 4 #Modo #3D...   \n",
       "2  RT @Fiicaan: Kalitta operated month old 777F h...   \n",
       "3  Aircraft, Vessels, or Vehicles-How Out of Stat...   \n",
       "4  RT @BBSAirport: We can’t wait to get back to d...   \n",
       "\n",
       "                                            Hashtags  Retweets  Favorites  \\\n",
       "0  [Titanfall, fanart, Modo, 3DArt, art, mecha, m...         1          0   \n",
       "1  [Titanfall, fanart, Modo, 3DArt, art, mecha, m...         1          0   \n",
       "2                            [avgeek, aviationphoto]        10          0   \n",
       "3                                                 []         0          0   \n",
       "4  [StaySafe, Airport, Timelapse, BusinessAviatio...         1          0   \n",
       "\n",
       "                       Location  \n",
       "0                                \n",
       "1                Buena Park, CA  \n",
       "2  Desearía estar en #MiEspaña   \n",
       "3                 Elk Grove, CA  \n",
       "4                     Worldwide  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 100 tweews on Pilot (person)\n",
    "all_tweets = get_tweets(\"#pilot\")\n",
    "pilot_tweets = all_tweets\n",
    "pilot_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Media Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting all the data, we analyzed it in order to answer questions about tags, users, and trending topic within our domain. Below are the answers to all the questions from the assignment as well as detailed descriptions on how we went about finding those answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are tags are associated with a person, place or thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine what tags were associated with each of our data frames, we first a function to extract tags from our data frame. The get_hashtags function loops through every row of the dataframe and looks at the 'Hashtag' column. Since some tweets have multiple tags, the function splits them up and replaces or removes all the blank spots. Each tag is then added to the overall list of tags and sent back.\n",
    "\n",
    "Now that this functions was created, we could simply call it with each domain- airport, airline, pilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract all tags from the data frame\n",
    "def get_hashtags(tweets):\n",
    "    all_hashtags = []\n",
    "    # Loop through each row in data frame\n",
    "    for index, row in tweets.iterrows():\n",
    "        # Extract all tags and split them up\n",
    "        tweet_hashtags = row['Hashtags']\n",
    "        for tag in tweet_hashtags:\n",
    "            # Remove any extra space and add to the list of all tags\n",
    "            tag = tag.replace(\"'\", \"\")\n",
    "            all_hashtags.append(tag.replace(\" \", \"\"))\n",
    " \n",
    "    # Remove all blank entries\n",
    "    while(\"\" in all_hashtags) : \n",
    "        all_hashtags.remove(\"\")\n",
    "        \n",
    "    return all_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all the tags associated with American Airlines (a thing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['americanairlines', 'covid', 'AmericanAirlines', 'Stock', 'AmericanAirlines', 'AmericanAirlines', 'AmericanAirlines', 'AmericanAirlines', 'AmericanAirlines', 'AmericanAirlines', 'COVID2019', 'Ame', 'AmericanAirlines', 'refund', 'insurance', 'Paramedic', 'americanairlines', 'AmericanAirlines', 'americanairlines', 'AmericanAirlines', 'AmericanAirlines', 'Stock', 'MarketScre', 'AmericanAirlines', 'AmericanAirlines', 'coronavirus', 'NewYork', 'AmericanAirlines', 'American', 'AmericanAirlines', 'FrequentFlierBenefits', 'FFbenefits', 'AmericanAirlines', 'AAfamily', 'AAfrequentflier', 'AmericanAirlines', 'coronavirus', 'NewYork', 'AmericanAirlines', 'United', 'NewYork', 'Flights', 'AviationNews', 'AmericanAirlines', 'virus', 'AmericanAirlines', 'Cargo', 'AmericanAirlines', 'COVID19', 'AmericanAirlines', 'AmericanAirlines', 'BusinessTravel', 'A', 'lax', 'klax', 'americanairlines', 'airplane', 'Boeing', 'Boeing777', 'AmericanAirlines', 'toky', 'RJTT', 'Narita', 'AmericanAirlines', 'Qantas', 'AmericanAirlines', 'Delta', 'DeltaAirlines', 'Covid_19', 'avgeek', 'avgeeks', 'COVID19', 'retired', 'klm', 'Airtransat', 'AmericanAirline', 'Covid_19', 'avgeek', 'avgeeks', 'COVID19', 'retired', 'klm', 'Airtransat', 'AmericanAirlines', 'AmericanAirlines', 'Stock', 'refund', 'insurance', 'Paramedic', 'refund', 'insurance', 'Paramedic', 'djalexreyes', 'deltaairlines', 'refund', 'insurance', 'Paramedic', 'AmericanAirlines', 'Avgeek', 'Avpix', 'Aviation', 'Photo', 'Photography', 'Planespotting', 'Ameri', 'Avgeek', 'Avpix', 'Aviation', 'Photo', 'Photography', 'Planespotting', 'Ameri', 'AmericanAirlines', 'AmericanAirlines', 'aa', 'Boeing757', 'Boeing', '757', 'regional', 'AmericanAirlines', 'B757', 'B757', 'B757', 'B757', 'AmericanAirlines', 'aa', 'Boeing757', 'Boeing', '757', 'B757', 'B757', 'B757', 'B757']\n"
     ]
    }
   ],
   "source": [
    "# Find and print most popular tags for American Airlines \n",
    "airline_tags = get_hashtags(airline_tweets)\n",
    "print(airline_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all the tags associated with Logan Airport (a place):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loganairport', 'loganairport', 'bostonfishpier', 'LoganAirport', 'Covid', 'newenglandpatriots', 'loganairport', 'boston', 'n95mask', 'repost', 'NewEngland', 'Patriots', 'LoganAirport', 'Boston', 'repost', 'NewEngland', 'Patriots', 'LoganAirport', 'Boston', 'repost', 'NewEngland', 'Patriots', 'LoganAirport', 'Boston', 'N95masks', 'Boston', 'LoganAirport', 'loganairport', 'loganairport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'LoganAirport', 'quincycab', '6174718294', 'quincyma', 'quincycab', '6174718294', 'quincycab', '6174718294', 'quincycab', '6174718294', 'loganairport', 'FlyingHome']\n"
     ]
    }
   ],
   "source": [
    "# Find and print most popular tags for Logan Airport\n",
    "airport_tags = get_hashtags(airport_tweets)\n",
    "print(airport_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all the tags associated with pilots (a person):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Titanfall', 'fanart', 'Modo', '3DArt', 'art', 'mecha', 'mech', 'respawn', 'gameart', 'gamedev', 'robot', 'military', 'scifi', 'l', 'Titanfall', 'fanart', 'Modo', '3DArt', 'art', 'mecha', 'mech', 'respawn', 'gameart', 'gamedev', 'robot', 'military', 'avgeek', 'aviationphoto', 'StaySafe', 'Airport', 'Timelapse', 'BusinessAviation', 'GeneralAv', 'StaySafe', 'Airport', 'Timelapse', 'BusinessAviation', 'FlightDeckMonday', 'flight', 'Pilot', 'IFR', 'businesscharter', 'privatejet', 'luxurymarbella', 'Comedy', 'Dramedy', 'TV', 'Series', 'pilot', 'episode', 'bible', 'Hollywood', 'studio', 'Comedy', 'Dramedy', 'TV', 'Series', 'pilot', 'episode', 'bible', 'Hollywood', 'pilot', 'publications', 'pilotlife', 'pilot', 'piloteyes', 'aviation', 'pilotview', 'instapilot', 'lifeasap', 'avgeek', 'aviationphotography', 'planespott', 'pilotlife', 'pilot', 'piloteyes', 'aviation', 'pilotview', 'instapilot', 'lifeasap', 'pilotlife', 'pilot', 'piloteyes', 'aviation', 'pilotview', 'video', 'pilot', 'mountainous', 'ridge', 'gaps', 'Central', 'Korea', 'pilot', 'flying', 'apache', 'ah64', 'apachehelicopter', 'helicopter', 'pilot', 'avgeek', 'aviationphoto', 'pilot', 'flying', 'inittogether', 'aviation', 'airplane', 'planes', 'jets', 'aircraft', 'pilot', 'helicopte', 'aviation', 'airplane', 'planes', 'jets', 'aviation', 'airplane', 'planes', 'jets', 'aircraft', 'pilot', 'MaltaMaritimePilots', 'Safehaven', 'Marine', 'built', 'Pilot', 'boat', 'FOXTROT', 'Grand', 'Harbour', 'Malta', 'avgeek', 'av', 'westworld', 'pilot', 'smh', 'Finland', 'avgeek', 'aviationdaily', 'flying', 'Airbus', 'aviation', 'jet', 'pilot', 'avgeek', 'aviationphotography', 'planespotting', 'aviati', 'avgeek', 'aviationphoto', 'aviation', 'airplane', 'planes', 'fsx', 'wingtipchallenge', 'aviation', 'flying', 'fun', 'pilot', 'sling2aircraft', 'pilottraining', 'wingtipchallenge', 'aviation', 'flying', 'fun', 'pilot', 'sling2aircraft', 'pilottraining', 'intro', 'wingtipchallenge', 'aviation', 'flying', 'fun', 'pilot', 'sling2aircraft', 'pilottraining', 'RVSMMonitoring', 'MarteUpdates', 'RVSM', 'Brazil', 'bizav', 'MaltaMaritimePilots', 'Safehaven', 'Marine', 'built', 'Pilot', 'boat', 'FOXTROT', 'Grand', 'Harbour', 'Malta', 'B737', 'boeing', 'pilot', 'pilotlife', 'CrewLife', 'airlines', 'aviation', 'aviation', 'airpla', 'aviation', 'MaltaMaritimePilots', 'Safehaven', 'Marine', 'built', 'Pilot', 'boat', 'FOXTROT', 'Grand', 'apache', 'ah64', 'apachehelicopter', 'helicopter', 'ShamelessSelfpromoSaturday', 'flightattendant', 'cabincrew', 'Pilot', 'airline', 'book', 'avgeek', 'aviationphotography', 'planespott', 'pilots', 'checklist', 'flight', 'Covid_19', 'coronavirus', 'Health', 'PPE', 'Science', 'StayHome', 'StaySafeStayHome', 'COVID', 'avgeek', 'ShamelessSelfpromoSaturday', 'flightattendant', 'cabincrew', 'Pilot', 'airline', 'book', 'Covid_19', 'coronavirus', 'Health', 'PPE', 'Science', 'StayHome', 'StaySafeStayHome', 'COVID', 'aviation', 'airplane', 'planes', 'jets', 'a', 'aviation', 'airplane', 'planes', 'jets', 'aircraft', 'pilot', 'helicopters', 'boats', 'ves', 'aviation', 'airplane', 'planes', 'youtube', 'GeneralAviation', 'pilot', 'WING', 'avgeek', 'aviationphoto', 'aviation', 'airplane', 'planes', 'jets', 'aircraft', 'pilot', 'helicopters', 'boats', 'avgeek', 'aviationphotography', 'planespott', 'bafta', 'premiere', 'pilot', 'screening', 'interneurs', 'tvseries', 'e', 'SelectaSpletzeug', 'Airplane', 'Wooden', 'Toy', 'Handcrafted', 'Germany', 'Pilot', 'bafta', 'premiere', 'pilot', 'screening', 'interneurs', 'tvseries', 'e', 'covid19', 'Coronavirus', 'britishairways', 'pilot', 'pandemic', 'food', 'delivery', 'driver', 'bafta', 'premiere', 'pilot', 'screen', 'avgeek', 'aviationphotography', 'planespott', 'p900', 'nikon', 'rescuehelicopter', 'helicopter', 'hero', 'lakemac', 'ourlakemac', 'aviation', 'airplane', 'planes', 'jets', 'aircraft', 'pil', '43MondayMotivation', '43airschool', 'aviation', 'aviationdrea', 'p900', 'nikon', 'rescuehelicopter', 'helicopter', 'hero', 'lakemac', 'mechanical', 'pilot', 'japanese', 'olympic', 'avgeek', 'aviationphoto', 'Eritrean', 'Asmara', 'black']\n"
     ]
    }
   ],
   "source": [
    "# Find and print most popular tags for pilot\n",
    "pilot_tags = get_hashtags(pilot_tweets)\n",
    "print(pilot_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What social media users are like other social media users in your domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which users in our domain are similar, we created a function called get_similar_users. The function takes in the data frame with all the tweet information and finds all users that tweeted using a particular tag. This is done by looping through all the tags, and any time the desired tag is found, the user that made that tweet is added to the list of similar users. This way, all users that tweet about a particular topic and use its specific tag are deemed to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find all users that used the same tag in their tweets\n",
    "def get_similar_users(tweets, desired_tag):\n",
    "    similar_users = []\n",
    "    # Loop through each row in data frame\n",
    "    for index, row in tweets.iterrows():\n",
    "        # Extract all tags and split them up\n",
    "        tweet_hashtags = row['Hashtags']\n",
    "        for tag in tweet_hashtags:\n",
    "            # Remove any extra space from tag\n",
    "            tag = tag.replace(\"'\", \"\")\n",
    "            tag = tag.replace(\" \", \"\")\n",
    "            # If the tag matches the desired tag, add user to the list of similar users\n",
    "            if tag == desired_tag:\n",
    "                similar_users.append(row['Screen_name'])\n",
    "        \n",
    "    return similar_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some similar users which all tweeted about B757- a specific airplane in American Airlines' fleet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JordanWeir45\n",
      "PlaneSpotIsCool\n",
      "Peter34080554\n",
      "TyphoonDobby\n",
      "avgeekjoseph\n",
      "NoCoffeeHere\n",
      "avgeek__\n",
      "iuY0jx47oBZfIlO\n"
     ]
    }
   ],
   "source": [
    "# Find all distinct users that tweeted about B757\n",
    "airline_users = get_similar_users(airline_tweets,'B757')\n",
    "for user in set(airline_users):\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some similar users which all tweeted about Quincy Cab- a specific cab company at Boston's Logan Airport:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365SouthShore\n",
      "YellowTaxiNow\n"
     ]
    }
   ],
   "source": [
    "# Find all distinct users that tweeted about Quincy Cab\n",
    "airport_users = get_similar_users(airport_tweets,'quincycab')\n",
    "for user in set(airport_users):\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some similar users which all tweeted about aviation photography:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetcitystar\n",
      "luisevanegas\n",
      "cargoeu\n",
      "aldersonjackson\n",
      "LandingsNL\n"
     ]
    }
   ],
   "source": [
    "# Find all distinct users that tweeted aviation photos\n",
    "pilot_users = get_similar_users(pilot_tweets,'aviationphoto')\n",
    "for user in set(pilot_users):\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What people, places or things are popular in your domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a list of most popular items in each domain, we created a function called popular_tags. This function uses the Counter method from the collections library to get a list of each tag used, accompanied by how many times it was used. It then uses the most_common method to extract the top 10 tags and print the tags (as well as the number of times they were used). This enabled us to see what topics were most popular for each set of tweets.\n",
    "\n",
    "To get most popular people in the domain, we created a function called popular_user. This function gets all usernames and their associated popularity (calculated by adding up the number of retweets and favorites). Then, it finds the top 3 users and prints their name as well as popularity (sum of retweets and favorites for a single tweet).\n",
    "\n",
    "Using these 2 functions, we were able to determine the most popular people, places, and things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get most popular tags\n",
    "def popular_tags(all_tags):\n",
    "    # Count all tags and get top 10 most used tags\n",
    "    tag_counts = collections.Counter(all_tags)\n",
    "    popular_tags = tag_counts.most_common(10)\n",
    "    # Print tags to the console\n",
    "    for tag in popular_tags:\n",
    "        print(tag[0] + \", \" + str(tag[1]))\n",
    "   \n",
    "# Function to find top users (num specifies how many top users to find)\n",
    "def popular_users(tweets, num):\n",
    "    users = []\n",
    "    popularity = []\n",
    "    # Loop through each row in data frame\n",
    "    for index, row in tweets.iterrows():\n",
    "        # Calculate popularity as sum of retweets and favorites\n",
    "        users.append(row['Screen_name'])\n",
    "        popularity.append(row['Retweets'] + row['Favorites'])\n",
    "    \n",
    "    # Find maximum popularity values and the associated users \n",
    "    for index in range(len(popularity)):\n",
    "        top_index = np.argsort(popularity)[-num:]\n",
    "        top_users = [users[i] for i in top_index]\n",
    "        top_popularity = [popularity[i] for i in top_index]\n",
    "    \n",
    "    # Print top users and their popularity\n",
    "    for index in range(len(top_users)):\n",
    "        print(\"User: \"+top_users[index]+\", Popularity: \"+str(top_popularity[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the most popular people, places, and things in the American Airline domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populart Places and Things\n",
      "AmericanAirlines, 33\n",
      "B757, 8\n",
      "americanairlines, 4\n",
      "refund, 4\n",
      "insurance, 4\n",
      "Paramedic, 4\n",
      "Stock, 3\n",
      "NewYork, 3\n",
      "COVID19, 3\n",
      "Boeing, 3\n",
      "\n",
      "Popular Users\n",
      "User: lantech19, Popularity: 10\n",
      "User: AMERICA_PARTII, Popularity: 10\n",
      "User: victorio_bdx, Popularity: 14\n",
      "User: sammy_palmerrr, Popularity: 929\n",
      "User: tothanines, Popularity: 929\n"
     ]
    }
   ],
   "source": [
    "# Find popular tags\n",
    "print(\"Populart Places and Things\")\n",
    "popular_tags(airline_tags)\n",
    "\n",
    "# Find top 5 popular users\n",
    "print()\n",
    "print(\"Popular Users\")\n",
    "popular_users(airline_tweets,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the most popular people, places, and things in the Logan Airport domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populart Places and Things\n",
      "LoganAirport, 25\n",
      "loganairport, 6\n",
      "Boston, 4\n",
      "quincycab, 4\n",
      "6174718294, 4\n",
      "repost, 3\n",
      "NewEngland, 3\n",
      "Patriots, 3\n",
      "bostonfishpier, 1\n",
      "Covid, 1\n",
      "\n",
      "Popular Users\n",
      "User: Winthropvikings, Popularity: 20\n",
      "User: chipsy231, Popularity: 20\n",
      "User: doogs1227, Popularity: 20\n",
      "User: winthropma02152, Popularity: 20\n",
      "User: JacqueGoddard, Popularity: 31\n"
     ]
    }
   ],
   "source": [
    "# Find popular tags\n",
    "print(\"Populart Places and Things\")\n",
    "popular_tags(airport_tags)\n",
    "\n",
    "# Find top 5 popular users\n",
    "print()\n",
    "print(\"Popular Users\")\n",
    "popular_users(airport_tweets,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the most popular people, places, and things in the pilot domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populart Places and Things\n",
      "pilot, 26\n",
      "aviation, 20\n",
      "avgeek, 13\n",
      "airplane, 9\n",
      "planes, 9\n",
      "Pilot, 7\n",
      "jets, 7\n",
      "flying, 6\n",
      "aviationphoto, 5\n",
      "aviationphotography, 5\n",
      "\n",
      "Popular Users\n",
      "User: flyAPM, Popularity: 22\n",
      "User: wolfmaster328, Popularity: 22\n",
      "User: aldersonjackson, Popularity: 32\n",
      "User: EritreanJournal, Popularity: 43\n",
      "User: aldersonjackson, Popularity: 55\n"
     ]
    }
   ],
   "source": [
    "# Find popular tags\n",
    "print(\"Populart Places and Things\")\n",
    "popular_tags(pilot_tags)\n",
    "\n",
    "# Find top 5 popular users\n",
    "print()\n",
    "print(\"Popular Users\")\n",
    "popular_users(pilot_tweets,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What people, places or things are trending in your domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_until(search_term,date):\n",
    "    all_tweets = []\n",
    "    for tweet in tweepy.Cursor(api.search, q=search_term,lang = \"en\",until=date).items(100):\n",
    "        #tweet_id = tweet.id\n",
    "        all_tweets += [{ 'Tweet_id': tweet.id,\n",
    "                'Screen_name':tweet.author.screen_name,\n",
    "                'Created_at':tweet.created_at,\n",
    "                'Tweet_text':tweet.text,\n",
    "                'Hashtags':re.findall(r\"#(\\w+)\",tweet.text),\n",
    "                'Retweets':tweet.retweet_count,\n",
    "                'Favorites':tweet.favorite_count,\n",
    "                'Location':tweet.user.location}]\n",
    "    return pd.DataFrame(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_trend = {1:[],2:[],3:[],4:[],5:[],6:[],7:[]}\n",
    "for day in range(7):\n",
    "    date = \"2020-04-0\" + str(day+1)\n",
    "    tweets = get_tweets_until(\"#airport\",date)\n",
    "    all_tags = get_hashtags(tweets)\n",
    "    tag_counts = collections.Counter(all_tags)\n",
    "    popular_tags = tag_counts.most_common(10)\n",
    "    tag_trend.update({day+1: popular_tags})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"1\": [[\"airport\", 48], [\"Orly\", 22], [\"Airport\", 14], [\"construction\", 12], [\"infrastructure\", 12], [\"Paris\", 4], [\"avgeek\", 3], [\"COVID19\", 3], [\"coronavirus\", 3], [\"covid\", 3]], \"2\": [[\"airport\", 26], [\"Airport\", 13], [\"aviation\", 11], [\"Airline\", 9], [\"Aviation\", 8], [\"avgeek\", 6], [\"COVID\", 6], [\"plane\", 5], [\"EmiratesSkyCargo\", 5], [\"cargo\", 5]], \"3\": [[\"news\", 18], [\"Airport\", 16], [\"airport\", 11], [\"Business\", 11], [\"travel\", 8], [\"SB19_JOSH\", 8], [\"aviation\", 8], [\"avgeek\", 8], [\"airplane\", 6], [\"vacation\", 5]], \"4\": [[\"Airport\", 22], [\"airport\", 18], [\"\\ud150\", 18], [\"\\u674e\\u6c38\\u94a6\", 18], [\"TEN\", 18], [\"\\u0e40\\u0e15\\u0e19\\u0e25\", 18], [\"NCT127\", 13], [\"\\uc5d4\\uc528\\ud2f012\", 13], [\"swfl\", 10], [\"aviation\", 10]], \"5\": [[\"airport\", 21], [\"Airport\", 13], [\"Boeing\", 11], [\"\\ud150\", 8], [\"\\u674e\\u6c38\\u94a6\", 8], [\"TEN\", 8], [\"\\u0e40\\u0e15\\u0e19\\u0e25\", 8], [\"KLM\", 8], [\"RoyalDutchAirlines\", 8], [\"Boeing787\", 8]], \"6\": [[\"Airport\", 27], [\"airport\", 23], [\"Florida\", 20], [\"FortMyers\", 18], [\"Fire\", 16], [\"vide\", 13], [\"coronavirus\", 7], [\"aviation\", 7], [\"LondonLutonAirport\", 5], [\"sunrise\", 5]], \"7\": [[\"airport\", 29], [\"Airport\", 28], [\"COVID19\", 8], [\"flight\", 8], [\"Germany\", 7], [\"OnThisDay\", 6], [\"Berlin\", 6], [\"News\", 6], [\"Airspace\", 6], [\"Corona\", 5]]}\n"
     ]
    }
   ],
   "source": [
    "test =json.dumps(tag_trend)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitioning to NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client['assignment3']\n",
    "collection=db['tweets']\n",
    "tweets = db.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_combo = [airline_tweets,airport_tweets,pilot_tweets]\n",
    "all_tweets = pd.concat(tweet_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1b2ae5c1308>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.insert_many(all_tweets.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweets']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names(include_system_collections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': [], 'count': 111}\n",
      "{'_id': ['LoganAirport'], 'count': 20}\n",
      "{'_id': ['AmericanAirlines'], 'count': 20}\n",
      "{'_id': ['avgeek', 'aviationphoto'], 'count': 10}\n",
      "{'_id': ['avgeek', 'aviationphotography', 'planespott'], 'count': 8}\n",
      "{'_id': ['refund', 'insurance', 'Paramedic'], 'count': 4}\n",
      "{'_id': ['wingtipchallenge',\n",
      "         'aviation',\n",
      "         'flying',\n",
      "         'fun',\n",
      "         'pilot',\n",
      "         'sling2aircraft',\n",
      "         'pilottraining'],\n",
      " 'count': 4}\n",
      "{'_id': ['aviation', 'airplane', 'planes'], 'count': 4}\n",
      "{'_id': ['bafta',\n",
      "         'premiere',\n",
      "         'pilot',\n",
      "         'screening',\n",
      "         'interneurs',\n",
      "         'tvseries',\n",
      "         'e'],\n",
      " 'count': 4}\n",
      "{'_id': ['B757'], 'count': 4}\n",
      "{'_id': ['pilot', 'flying'], 'count': 4}\n",
      "{'_id': ['MaltaMaritimePilots',\n",
      "         'Safehaven',\n",
      "         'Marine',\n",
      "         'built',\n",
      "         'Pilot',\n",
      "         'boat',\n",
      "         'FOXTROT',\n",
      "         'Grand',\n",
      "         'Harbour',\n",
      "         'Malta'],\n",
      " 'count': 4}\n",
      "{'_id': ['pilotlife',\n",
      "         'pilot',\n",
      "         'piloteyes',\n",
      "         'aviation',\n",
      "         'pilotview',\n",
      "         'instapilot',\n",
      "         'lifeasap'],\n",
      " 'count': 4}\n",
      "{'_id': ['ShamelessSelfpromoSaturday',\n",
      "         'flightattendant',\n",
      "         'cabincrew',\n",
      "         'Pilot',\n",
      "         'airline',\n",
      "         'book'],\n",
      " 'count': 4}\n",
      "{'_id': ['loganairport'], 'count': 3}\n",
      "{'_id': ['quincycab', '6174718294'], 'count': 3}\n",
      "{'_id': ['repost', 'NewEngland', 'Patriots', 'LoganAirport', 'Boston'],\n",
      " 'count': 3}\n",
      "{'_id': ['businesscharter', 'privatejet', 'luxurymarbella'], 'count': 2}\n",
      "{'_id': ['SelectaSpletzeug',\n",
      "         'Airplane',\n",
      "         'Wooden',\n",
      "         'Toy',\n",
      "         'Handcrafted',\n",
      "         'Germany',\n",
      "         'Pilot'],\n",
      " 'count': 2}\n",
      "{'_id': ['p900', 'nikon', 'rescuehelicopter', 'helicopter', 'hero', 'lakemac'],\n",
      " 'count': 2}\n",
      "{'_id': ['apache', 'ah64', 'apachehelicopter', 'helicopter', 'pilot'],\n",
      " 'count': 2}\n",
      "{'_id': ['avgeek', 'aviationphotography', 'planespotting', 'aviati'],\n",
      " 'count': 2}\n",
      "{'_id': ['MaltaMaritimePilots',\n",
      "         'Safehaven',\n",
      "         'Marine',\n",
      "         'built',\n",
      "         'Pilot',\n",
      "         'boat',\n",
      "         'FOXTROT',\n",
      "         'Grand'],\n",
      " 'count': 2}\n",
      "{'_id': ['Titanfall',\n",
      "         'fanart',\n",
      "         'Modo',\n",
      "         '3DArt',\n",
      "         'art',\n",
      "         'mecha',\n",
      "         'mech',\n",
      "         'respawn',\n",
      "         'gameart',\n",
      "         'gamedev',\n",
      "         'robot',\n",
      "         'military'],\n",
      " 'count': 2}\n",
      "{'_id': ['GeneralAviation', 'pilot', 'WING'], 'count': 2}\n",
      "{'_id': ['pilots', 'checklist', 'flight'], 'count': 2}\n",
      "{'_id': ['StaySafe', 'Airport', 'Timelapse', 'BusinessAviation', 'GeneralAv'],\n",
      " 'count': 2}\n",
      "{'_id': ['Covid_19',\n",
      "         'coronavirus',\n",
      "         'Health',\n",
      "         'PPE',\n",
      "         'Science',\n",
      "         'StayHome',\n",
      "         'StaySafeStayHome',\n",
      "         'COVID',\n",
      "         'avgeek'],\n",
      " 'count': 2}\n",
      "{'_id': ['youtube'], 'count': 2}\n",
      "{'_id': ['Comedy',\n",
      "         'Dramedy',\n",
      "         'TV',\n",
      "         'Series',\n",
      "         'pilot',\n",
      "         'episode',\n",
      "         'bible',\n",
      "         'Hollywood'],\n",
      " 'count': 2}\n",
      "{'_id': ['fsx'], 'count': 2}\n",
      "{'_id': ['bafta', 'premiere', 'pilot', 'screen'], 'count': 2}\n",
      "{'_id': ['wingtipchallenge',\n",
      "         'aviation',\n",
      "         'flying',\n",
      "         'fun',\n",
      "         'pilot',\n",
      "         'sling2aircraft',\n",
      "         'pilottraining',\n",
      "         'intro'],\n",
      " 'count': 2}\n",
      "{'_id': ['Covid_19',\n",
      "         'coronavirus',\n",
      "         'Health',\n",
      "         'PPE',\n",
      "         'Science',\n",
      "         'StayHome',\n",
      "         'StaySafeStayHome',\n",
      "         'COVID'],\n",
      " 'count': 2}\n",
      "{'_id': ['inittogether'], 'count': 2}\n",
      "{'_id': ['avgeek', 'av'], 'count': 2}\n",
      "{'_id': ['pilot', 'publications'], 'count': 2}\n",
      "{'_id': ['aviation', 'airplane', 'planes', 'jets', 'aircraft', 'pilot'],\n",
      " 'count': 2}\n",
      "{'_id': ['Comedy',\n",
      "         'Dramedy',\n",
      "         'TV',\n",
      "         'Series',\n",
      "         'pilot',\n",
      "         'episode',\n",
      "         'bible',\n",
      "         'Hollywood',\n",
      "         'studio'],\n",
      " 'count': 2}\n",
      "{'_id': ['westworld', 'pilot', 'smh'], 'count': 2}\n",
      "{'_id': ['aviation', 'airplane', 'planes', 'jets', 'a'], 'count': 2}\n",
      "{'_id': ['B737',\n",
      "         'boeing',\n",
      "         'pilot',\n",
      "         'pilotlife',\n",
      "         'CrewLife',\n",
      "         'airlines',\n",
      "         'aviation'],\n",
      " 'count': 2}\n",
      "{'_id': ['StaySafe', 'Airport', 'Timelapse', 'BusinessAviation'], 'count': 2}\n",
      "{'_id': ['avgeek',\n",
      "         'aviationdaily',\n",
      "         'flying',\n",
      "         'Airbus',\n",
      "         'aviation',\n",
      "         'jet',\n",
      "         'pilot'],\n",
      " 'count': 2}\n",
      "{'_id': ['Central', 'Korea'], 'count': 2}\n",
      "{'_id': ['video', 'pilot', 'mountainous', 'ridge', 'gaps'], 'count': 2}\n",
      "{'_id': ['Avgeek',\n",
      "         'Avpix',\n",
      "         'Aviation',\n",
      "         'Photo',\n",
      "         'Photography',\n",
      "         'Planespotting',\n",
      "         'Ameri'],\n",
      " 'count': 2}\n",
      "{'_id': ['apache', 'ah64', 'apachehelicopter', 'helicopter'], 'count': 2}\n",
      "{'_id': ['p900',\n",
      "         'nikon',\n",
      "         'rescuehelicopter',\n",
      "         'helicopter',\n",
      "         'hero',\n",
      "         'lakemac',\n",
      "         'ourlakemac'],\n",
      " 'count': 2}\n",
      "{'_id': ['aviation'], 'count': 2}\n",
      "{'_id': ['Titanfall',\n",
      "         'fanart',\n",
      "         'Modo',\n",
      "         '3DArt',\n",
      "         'art',\n",
      "         'mecha',\n",
      "         'mech',\n",
      "         'respawn',\n",
      "         'gameart',\n",
      "         'gamedev',\n",
      "         'robot',\n",
      "         'military',\n",
      "         'scifi',\n",
      "         'l'],\n",
      " 'count': 2}\n",
      "{'_id': ['FlightDeckMonday', 'flight', 'Pilot', 'IFR'], 'count': 2}\n",
      "{'_id': ['mechanical', 'pilot', 'japanese', 'olympic'], 'count': 2}\n",
      "{'_id': ['Eritrean', 'Asmara', 'black'], 'count': 2}\n",
      "{'_id': ['43MondayMotivation', '43airschool', 'aviation', 'aviationdrea'],\n",
      " 'count': 2}\n",
      "{'_id': ['pilotlife', 'pilot', 'piloteyes', 'aviation', 'pilotview'],\n",
      " 'count': 2}\n",
      "{'_id': ['AmericanAirlines', 'Stock'], 'count': 2}\n",
      "{'_id': ['RVSMMonitoring', 'MarteUpdates', 'RVSM', 'Brazil', 'bizav'],\n",
      " 'count': 2}\n",
      "{'_id': ['AmericanAirlines', 'coronavirus', 'NewYork'], 'count': 2}\n",
      "{'_id': ['Finland'], 'count': 2}\n",
      "{'_id': ['aviation', 'airplane', 'planes', 'jets', 'aircraft', 'pil'],\n",
      " 'count': 2}\n",
      "{'_id': ['aviation', 'airpla'], 'count': 2}\n",
      "{'_id': ['aviation',\n",
      "         'airplane',\n",
      "         'planes',\n",
      "         'jets',\n",
      "         'aircraft',\n",
      "         'pilot',\n",
      "         'helicopte'],\n",
      " 'count': 2}\n",
      "{'_id': ['aviation', 'airplane', 'planes', 'jets'], 'count': 2}\n",
      "{'_id': ['americanairlines'], 'count': 2}\n",
      "{'_id': ['covid19',\n",
      "         'Coronavirus',\n",
      "         'britishairways',\n",
      "         'pilot',\n",
      "         'pandemic',\n",
      "         'food',\n",
      "         'delivery',\n",
      "         'driver'],\n",
      " 'count': 2}\n",
      "{'_id': ['aviation',\n",
      "         'airplane',\n",
      "         'planes',\n",
      "         'jets',\n",
      "         'aircraft',\n",
      "         'pilot',\n",
      "         'helicopters',\n",
      "         'boats',\n",
      "         'ves'],\n",
      " 'count': 2}\n",
      "{'_id': ['aviation',\n",
      "         'airplane',\n",
      "         'planes',\n",
      "         'jets',\n",
      "         'aircraft',\n",
      "         'pilot',\n",
      "         'helicopters',\n",
      "         'boats'],\n",
      " 'count': 2}\n",
      "{'_id': ['Covid_19',\n",
      "         'avgeek',\n",
      "         'avgeeks',\n",
      "         'COVID19',\n",
      "         'retired',\n",
      "         'klm',\n",
      "         'Airtransat',\n",
      "         'AmericanAirline'],\n",
      " 'count': 1}\n",
      "{'_id': ['Covid_19',\n",
      "         'avgeek',\n",
      "         'avgeeks',\n",
      "         'COVID19',\n",
      "         'retired',\n",
      "         'klm',\n",
      "         'Airtransat'],\n",
      " 'count': 1}\n",
      "{'_id': ['BusinessTravel', 'A'], 'count': 1}\n",
      "{'_id': ['quincycab', '6174718294', 'quincyma'], 'count': 1}\n",
      "{'_id': ['AmericanAirlines', 'Stock', 'MarketScre'], 'count': 1}\n",
      "{'_id': ['airplane',\n",
      "         'Boeing',\n",
      "         'Boeing777',\n",
      "         'AmericanAirlines',\n",
      "         'toky',\n",
      "         'RJTT',\n",
      "         'Narita'],\n",
      " 'count': 1}\n",
      "{'_id': ['Ame'], 'count': 1}\n",
      "{'_id': ['loganairport', 'bostonfishpier'], 'count': 1}\n",
      "{'_id': ['loganairport', 'FlyingHome'], 'count': 1}\n",
      "{'_id': ['AmericanAirlines', 'American'], 'count': 1}\n",
      "{'_id': ['Qantas', 'AmericanAirlines', 'Delta', 'DeltaAirlines'], 'count': 1}\n",
      "{'_id': ['AmericanAirlines', 'United', 'NewYork', 'Flights'], 'count': 1}\n",
      "{'_id': ['djalexreyes', 'deltaairlines'], 'count': 1}\n",
      "{'_id': ['AviationNews', 'AmericanAirlines', 'virus'], 'count': 1}\n",
      "{'_id': ['FrequentFlierBenefits',\n",
      "         'FFbenefits',\n",
      "         'AmericanAirlines',\n",
      "         'AAfamily',\n",
      "         'AAfrequentflier'],\n",
      " 'count': 1}\n",
      "{'_id': ['AmericanAirlines', 'COVID19'], 'count': 1}\n",
      "{'_id': ['AmericanAirlines', 'Cargo'], 'count': 1}\n",
      "{'_id': ['AmericanAirlines', 'aa', 'Boeing757', 'Boeing', '757', 'regional'],\n",
      " 'count': 1}\n",
      "{'_id': ['N95masks', 'Boston', 'LoganAirport'], 'count': 1}\n",
      "{'_id': ['lax', 'klax', 'americanairlines'], 'count': 1}\n",
      "{'_id': ['newenglandpatriots', 'loganairport', 'boston', 'n95mask'], 'count': 1}\n",
      "{'_id': ['LoganAirport', 'Covid'], 'count': 1}\n",
      "{'_id': ['COVID2019'], 'count': 1}\n"
     ]
    }
   ],
   "source": [
    "for tt in tweets.aggregate([ {\"$group\": {\"_id\": \"$Hashtags\", \"count\": {\"$sum\": 1}}},{\"$sort\":{\"count\":-1}}  ]):\n",
    "    pprint.pprint(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPORT\n",
    "\n",
    "Blah, balh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "\n",
    "The primary focus of this assignment was learnign how to analyze social media data, as well as convert a SQL/relational database into a NoSQL database (MongoDB, specifically). We expanded upon our database from Assignment 2 by adding twitter data to it, and analyzing it in order to answer questions about popular topic within our domain. We then converted our database into MongoDB by first denormalizing it, and then establishing a connection with a MongoDB server and transfering over our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTION\n",
    "On our own: \n",
    "\n",
    "External Sources: \n",
    "\n",
    "Provided by Professor:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CITATIONS\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets (Twitter API Documentation- help with collecting Twitter data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LICENSE\n",
    "Copyright 2020 Anja Deric, Karan Soni\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated \n",
    "documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the \n",
    "rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\n",
    "persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the \n",
    "Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE \n",
    "WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR \n",
    "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR \n",
    "OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
